{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1d369f-0c18-4daa-9356-5937a4dcce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bee57c5-57bb-4d90-8941-b11950d92bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents = pd.read_csv('../data/MA3_finished.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d9ab49-c33a-4c03-87e1-c3b8961ab635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten in Trainigs/Test/Entwicklungs Daten aufteilen\n",
    "\n",
    "#featureselection\n",
    "obj_bool_features = df_accidents[['Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit',\n",
    "                         'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
    "                         'Sunrise_Sunset']]\n",
    "#encode features above\n",
    "le = LabelEncoder()\n",
    "#create copy of df\n",
    "df_encoded = pd.DataFrame()\n",
    "#LabelEncoder can only encode one column at a time --> forloop\n",
    "#obj_bool_feat = le.fit_transform(obj_bool_features)\n",
    "for feature in obj_bool_features:\n",
    "    df_encoded[feature] = le.fit_transform(df_accidents[feature])\n",
    "\n",
    "#float/int features\n",
    "float_int_features = df_accidents[['Severity','Start_Lng', 'Start_Lat', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)',]]\n",
    "\n",
    "for feature in float_int_features:\n",
    "    df_encoded[feature] = df_accidents[feature]\n",
    "\n",
    "#set Target\n",
    "target = df_encoded['Severity']\n",
    "#set features\n",
    "features = df_encoded.drop(columns=['Severity'])\n",
    "#scale features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "#Split Trainings/Test Daten 80/20 \n",
    "features_train, features_test1, target_train, target_test1 = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "#Split Test in Entwicklungs und echten Daten 50/50\n",
    "features_dev, features_test, target_dev, target_test = train_test_split(features_test1, target_test1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb59c5c-112f-4074-8781-c5d3c6c1bc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtzahl Datenpunkte Training:  5641244\n",
      "Anzahl Kategorie 1 51977\n",
      "Anzahl Kategorie 2 4537583\n",
      "Anzahl Kategorie 3 908712\n",
      "Anzahl Kategorie 4 142972\n"
     ]
    }
   ],
   "source": [
    "# Übersicht über Klassen in den Trainingsdaten\n",
    "\n",
    "print(\"Gesamtzahl Datenpunkte Training: \", len(target_train))\n",
    "\n",
    "# Range(0,4) gibt bei Kategorie 0 = 0\n",
    "# Range (1,6) gibt bei Katg. 5 = 0\n",
    "# deswegen (1,5) (4 Severitys)\n",
    "for i in range(1,5):\n",
    "    print(\"Anzahl Kategorie\", str(i), list(target_train).count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73b6ef5-f238-420e-9e72-9c9efbb4347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtzahl Datenpunkte Dev:  705156\n",
      "Anzahl Kategorie 1 6635\n",
      "Anzahl Kategorie 2 567067\n",
      "Anzahl Kategorie 3 113583\n",
      "Anzahl Kategorie 4 17871\n"
     ]
    }
   ],
   "source": [
    "# Entwicklungsdaten\n",
    "print(\"Gesamtzahl Datenpunkte Dev: \", len(target_dev))\n",
    "for i in range(1,5):\n",
    "    print(\"Anzahl Kategorie\", str(i), list(target_dev).count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a084cc-5670-45f1-8e98-c3d0477ad13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705156 705156\n",
      "Der gewichtete F1-Score für die konstante Vorhersage '2' ist:  0.7164639019274487\n"
     ]
    }
   ],
   "source": [
    "# Vorhersage-Array bauen: Für jedes Element der Entwicklungsdaten Klasse '2' (Bei uns Severity-Stufe 2) vorhersagen\n",
    "pred = np.full(len(target_dev),2)\n",
    "\n",
    "print(len(target_dev), len(pred))\n",
    "\n",
    "#Berechnung f1-score\n",
    "f1 = f1_score(target_test, pred, average='weighted')\n",
    "\n",
    "print(\"Der gewichtete F1-Score für die konstante Vorhersage '2' ist: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d99b63-3801-4003-9e84-a76c3c94997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1-score von 0.71 ist annehmbar --> gute Blaance zwischen Präzision und Recall (Der Wert könnte weiterhoch gepusht werden indem\n",
    "# mehr Outliner eliminert werden wprden ODER Modellwechsel ODER featureauswahl verbessern)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
